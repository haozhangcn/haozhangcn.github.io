---
layout: post
title: “Automatic Soil Desiccation Crack Recognition Using Deep Learning” was selected as the insightful paper on Artificial Intelligence and Statistics in geotechnics published in the decade 2013‑2023.
date: 2023-10-27 07:59:00-0400
inline: false
related_posts: false
---
“Automatic Soil Desiccation Crack Recognition Using Deep Learning” was selected as [the insightful paper on Artificial Intelligence and Statistics in geotechnics published in the decade 2013‑2023](https://www.icevirtuallibrary.com/page/ice-news/geot75anniversaryprogramme)
---

[Automatic Soil Desiccation Crack Recognition Using Deep Learning](https://doi.org/10.1680/jgeot.20.P.091)<br>
 Jin-Jian Xu, <u><b>Hao Zhang</b></u>, Chao-Sheng Tang, Qing Cheng, Bo Liu, and Bin Shi<br>
 *Géotechnique*, Volume 72 Issue 4, April, 2022, pp. 337-349. doi: 10.1680/jgeot.20.P.091.
[[poster](https://www.icevirtuallibrary.com/pb-assets/GEOT%2075th%20Event/S3%20P5%20G%C3%A9otechnique%20Poster%20-%20Automatic%20soil%20desiccation%20crack%20recognition%20using%20deep%20learning-XJJ-1694727350.pdf)]

## Abstract
<small>
Soil desiccation cracking is a common natural phenomenon. The existence of cracks can negatively impact both the mechanical and hydraulic properties of soil. Accurate acquisition of soil crack networks is not only the basis for obtaining the relevant geometrical parameters of crack networks, but also an important foundation and premise for further study about the formation mechanism of shrinkage and desiccation cracking. This study proposes a new automatic soil cracks recognition method based on a U-Net convolutional neural network (CNN) architecture for segmentation on soil desiccation crack images. The backbone of the U-Net encoder is selected as ResNet and a new loss function combining both binary cross-entropy (BCE) loss and dice loss is used during the training stage to fit an imbalance problem. Subsequently, the U-Net with an encoder based on ResNet and a decoder part is trained from end to end on a subset of 524 labelled crack images with 224×224 pixels for semantic segmentation. The U-Net architecture achieves 94·38%, 74·43% and 81·13% for precision, recall and dice scores on test sets, which are better than all results using the Otsu threshold method employed in the traditional crack image processing technique. Experimental results reveal that deep learning can achieve higher accuracy than the traditional method (binarisation by thresholding) in quantifying surface crack ratio, average crack width, total crack length and crack number. Moreover, deep learning can not only accurately identify cracks or spots by means of crack edge features, but also can accurately separate soil cracks and clod areas under a bad photographing condition (such as uneven illumination, a field environment or poor photographing angle). Overall, the proposed deep learning-based method presents a satisfactory performance in soil crack image recognition and quantification. It may also be applied to other materials with cracks.
</small>

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/2021-01-11_crack.jpg" title="crack" class="img-fluid rounded z-depth-1" %}
    </div>
</div>

## Highlights

`First paper that overcome soil crack recognition porlbem using deep learning`

1. A new automatic soil cracks recognition method based on a U-Net convolutional neural network (CNN) architecture for segmentation on soil desiccation crack images. 
2. The backbone of the U-Net encoder is selected as ResNet and a new loss function combining both binary cross-entropy (BCE) loss and dice loss is used during the training stage to fit an imbalance problem. 
3. Experimental results reveal that deep learning can achieve higher accuracy than the traditional method (binarisation by thresholding) in quantifying surface crack ratio, average crack width, total crack length and crack number.


## Citation
<pre>
@article{xu2020automatic,
  title={Automatic Soil Desiccation Crack Recognition Using Deep Learning},
  author={Xu, Jin-Jian and Zhang, Hao and Tang, Chao-Sheng and Cheng, Qing and Liu, Bo and Shi, Bin},
  journal={G{\'e}otechnique},
  volume = {72},
  number = {4},
  pages = {337-349},
  year = {2022},
  doi = {10.1680/jgeot.20.P.091},
  publisher={Thomas Telford Ltd}
}
</pre>
